<!DOCTYPE html>
<html>
  <title>VIS 2018 Tutorial</title>
  <xmp theme="simplex" style="display:none;">
# Tutorial on Recent Feature Tracking Techniques

The purpose of this tutorial is to review feature tracking, which is a traditional but still core research topic in scientific visualization.  In general, feature tracking aims at characterizing and understanding the evolution of features in time-varying scientific datasets, including scalar and vector fields.  The tutorial has two main sessions: the first session will review general techniques including statistics, topology, and combinatorial based feature tracking algorithms; the second session will then present specific feature tracking algorithms for complex-valued scalar fields and flow fields.  The tutorial will also organize a short panel discussion on future research directions on feature tracking.


## Organizers

* [Hanqi Guo](http://www.mcs.anl.gov/~hguo/), Argonne National Laboratory
* [Harsh Bhatia](http://www.sci.utah.edu/~hbhatia/), Lawrence Livermore National Laboratory
* [Tino Weinkauf](http://www.csc.kth.se/~weinkauf/), KTH Stockholm
* [Gunther H. Weber](http://crd.lbl.gov/q/ghweber/), Lawrence Berkeley National Laboratory and University of California, Davis
* [Han-Wei Shen](http://web.cse.ohio-state.edu/~shen.94/), The Ohio State University


## Schedule

The tutorial is from 2:20pm to 6:00pm on Sunday, October 21, 2018:

* Talk 1: Han-Wei Shen, 35 minutes
* Talk 2: Gunther Weber, 35 minutes
* Talk 3: Tino Weinkauf, 35 minutes
* Coffee Break, 20 minutes
* Talk 4: Hanqi Guo, 35 minutes
* Talk 5: Harsh Bhatia, 35 minutes
* Panel Discussion and Closing, 15 minutes


## Talks

### Statistics Based Feature Extraction and Tracking (Han-Wei Shen)

[Slides](shen.pdf)

<b>Abstract:</b> 
Scientists overview and identify regions of interest by transforming
data into compact information descriptors that characterize simulation
results and allow detailed analysis on demand. Among many existing
feature descriptors, statistical information derived from data samples
is a promising approach to taming the big data avalanche because data
distributions computed from a population can compactly describe the
presence and characteristics of salient data features with minimal
data movement. The ability to computationally summarize and process
data using distributions also provides an efficient and representative
capture of information that can adjust to size and resource
constraints, with the added benefit that uncertainty associated with
the results can be quantified and communicated.  In this tutorial, I will
discuss several recent works on using distributions as a new paradiagm for
representing large scale scientific data sets.  The goal is to
ensure that scientists can easily obtain an overview of the entire
data set regardless of the size of the simulation output; understand
the characteristics and locations of features; easily interact with
the data and select regions and features of interest; and perform all
the analysis tasks with a small memory footprint.

<b>Speaker:</b>
Han-Wei Shen is a full professor at The Ohio State University. He has
over two decades of experience in large scale data visualization and
analysis. He has served as an Associate Editor for IEEE Transactions on Visualization and 
Computer Graphics, a  paper co-chair for Pacific, and a paper-co chair for IEEE SciVis. He was 
also a member of IEEE Visualization Executive Committee, and is currently a member of 
IEEE SciVis Steering Committee. Prof. Shen  has participated in many US federal big data research
initiatives, including the NSF's big data program,multiple Department of Energy (DOE)’s Scientific Data Management and
Analysis at Extreme Scale projects, and DOE's SciDAC Institute of Scalable Data Management, Analysis, and Visualization.  Before joining
Ohio State, he was a research scientist at NASA Ames Research Center in Mountain View California between 1996 and 1999. His primary
research interests are scientific visualization and computer graphics. Professor Shen is a winner of National Science Foundation's
CAREER award and US Department of Energy's Early Career Principal Investigator Award. He also won the outstanding teaching award three
times from the Department of Computer Science and Engineering at the Ohio State University.

### Topology-based feature tracking in scalar fields (Gunther Weber)

[Slides](weber.pdf)

<b>Abstract:</b>
With increasing size and dimensionality, time-varying data become difficult to visualize and analyze. One solution to this challenge is to detect features, i.e., salient data subsets, at each point in time and track their evolution to obtain more compact and less cluttered visualizations. We focus on scalar fields, where many feature definitions are based on super-/sub-level sets and isosurfaces. Starting with overlap tracking, feature tracking approaches have evolved considerably over the years. Topology-based methods provide solid theoretical foundation for correlating and tracking features. We will review feature definitions ins scalar fields based on super-/sub-level sets and isosurfaces and how they relate to topological structures like merge-tree, contour tree and Reeb graph. Subsequently, we will provide an overview of topology-based methods that use contour trees, merge-trees and the Reeb graph and discuss their respective advantages and disadvantages. Finally, we will review presentation of tracking information, including tracking features at multiple levels and how effective representation relates to the chosen tracking approach.

<b>Speaker:</b>
Gunther H. Weber received a Ph.D. in computer science, with a focus on computer graphics and visualization, from the University of Kaiserslautern, Germany in 2003. He is currently a Staff Scientist in the Computational Research Division at the Lawrence Berkeley National Laboratory (LBNL), where he serves as Deputy Group Lead of the Data Analysis and Visualization Group in the Data Science and Technology Department. Gunther Weber is also an Adjunct Associate Professor of Computer Science at the University of California, Davis. His  research interests include computer graphics, scientific visualization, data analysis with using topological methods, parallel and distributed computing for visualization and data analysis applications, hierarchical data representation methods, and bioinformatics. He has extensive experience in working with researchers from diverse science and engineering fields, including applied numerical computing, combustion simulation, gene expression, medicine, civil engineering, cosmology, climate and particle accelerator modeling. 


### Feature-Tracking using Discrete Methods (Tino Weinkauf)

[Slides](weinkauf.pdf)

<b>Abstract:</b>
We explore several different feature tracking techniques based on topological descriptions of scalar data. This includes tracking critical points using the discrete Morse-Smale complex as well as tracking regions defined by subtrees of merge trees. The talk focuses on discrete methods that allow for combinatorial algorithms. Furthermore, we extend the idea of feature comparison to spatio-temporal features and explore how this helps in understanding time-dependent data.

<b>Speaker:</b>
Tino Weinkauf received his diploma in computer science from the
University of Rostock in 2000. From 2001, he worked on featurebased
flow visualization and topological data analysis at Zuse Institute
Berlin. He received his Ph.D. in computer science from the University
of Magdeburg in 2008. In 2009 and 2010, he worked as a postdoc
and adjunct assistant professor at the Courant Institute of Mathematical
Sciences at New York University. He started his own group in
2011 on Feature-Based Data Analysis in the Max Planck Center for
Visual Computing and Communication, Saarbrcken. Since 2015, he
holds the Chair of Visualization at KTH Stockholm. His current research
interests focus on flow analysis, discrete topological methods,
and information visualization.



### Feature Extraction and Tracking in Complex-Valued Scalar Fields (Hanqi Guo)

[Slides](guo.pdf)

<b>Abstract:</b>
Topological singularities, or vortices, in 3D complex-valued scalar fields are the most important features in many scientific applications including superconductivity, superfluidity, and Bose-Einstein condensation.  This talk presents a method for the extraction and tracking of vortices for both structured and unstructured mesh superconductivity simulations.  This method represents each vortex line as a connected graph extracted from the discretized field in both space and time.  For a time-varying discrete dataset, our vortex extraction and tracking method is as accurate as the data discretization. We then apply 3D visualization and 2D event diagrams to the extraction and tracking results to help scientists understand vortex dynamics and macroscale superconductor behavior in greater detail than previously possible.  In addition, we present an workflow that extracts and tracks vortices in situ.

<b>Speaker:</b>
Hanqi Guo is an assistant computer scientist in the Mathematics and Computer Science Division at Argonne National Laboratory.  He received his PhD degree in computer science from Peking University in 2014, and the BS degree in mathematics and applied mathematics from Beijing University of Posts and Telecommunications in 2009. His research interests are mainly on uncertainty visualization, flow visualization, and large-scale scientific data visualization.



### Feature extraction and tracking using vector field decompositions (Harsh Bhatia)

[Slides](bhatia.pdf)

<b>Abstract:</b>
Extraction and time tracking of flow features is critical to explore the underlying phenomena, and several types of approaches have been proposed to this end. In this session, I will discuss a series of techniques that utilize vector field decompositions to extract and track coherent features in flow fields. Starting with Polthier and Preuß's work on computing the Helmholtz-Hodge decomposition on triangulations and its applications to compute critical points, I will talk about several improvements, including different applications as well as 3D computations. I will also discuss the more-recently proposed <em>natural Helmholtz-Hodge decomposition</em>, and present how it has been used to extract temporally coherent features through internal reference frames.

<b>Speaker:</b>
Harsh Bhatia is a Computer Scientist at the Center for Applied Scientific Computing at Lawrence Livermore National Laboratory (LLNL). Prior to his appointment, he received his Ph.D. degree in Computing from the Scientific Computing and Imaging (SCI) institute, The University of Utah, and finished post-doctoral research at LLNL. Harsh has keen interest in scientific and information visualization, high-performance computing, large-scale data analysis, and has worked extensively in flow visualization techniques. 

</xmp>
<script src="./strapdown.js"></script>

</html>
